{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eca851c5-ab4a-4e9a-ad7a-c86f04b01ea3",
      "metadata": {
        "id": "eca851c5-ab4a-4e9a-ad7a-c86f04b01ea3",
        "outputId": "e800bd33-c42c-4178-e42f-8553969a8de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from datasets) (2.1.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from datasets) (3.10.8)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from datasets) (0.25.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: colorama in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from pandas) (2.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install pandas\n",
        "\n",
        "from collections import defaultdict\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a7adf3-2aff-4276-ab4c-4695e977209d",
      "metadata": {
        "id": "55a7adf3-2aff-4276-ab4c-4695e977209d",
        "outputId": "d95ad48e-f753-4852-9033-d3c5d4764d62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FileObject(id='file-MNOOpCzRXsKM62tzknqCXeBI', bytes=35974, created_at=1728021223, filename='synthetic_qa_pairs_finetune_gpt3.5.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"\"\n",
        "\n",
        "client.files.create(\n",
        "  file=open(\"synthetic_qa_pairs_finetune_gpt3.5.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "600c01a8-da7e-4c04-b8ae-26cee4ddf071",
      "metadata": {
        "id": "600c01a8-da7e-4c04-b8ae-26cee4ddf071",
        "outputId": "bb94d96e-db75-4eca-9703-951f2b14307d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num examples: 97\n",
            "First example:\n",
            "{'role': 'system', 'content': 'You are a helpful assistant.'}\n",
            "{'role': 'user', 'content': 'How do I unsubscribe from the monthly plan?'}\n",
            "{'role': 'assistant', 'content': \"To unsubscribe from the monthly plan, go to the subscription management dropdown in your dashboard, select 'Manage Subscription,' choose the 'Cancel Subscription' option, and confirm your decision. You will retain access to premium features until the current billing period ends.\"}\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "with open(\"synthetic_qa_pairs_finetune_gpt3.5.jsonl\", 'r', encoding='utf-8') as f:\n",
        "    file = [json.loads(line) for line in f]\n",
        "\n",
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(file))\n",
        "print(\"First example:\")\n",
        "for message in file[0][\"messages\"]:\n",
        "    print(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04f7bd7c-d738-4ff9-8779-89c074e906a0",
      "metadata": {
        "id": "04f7bd7c-d738-4ff9-8779-89c074e906a0",
        "outputId": "27662e30-5615-4a7d-e9b8-4df901083dd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No errors found\n"
          ]
        }
      ],
      "source": [
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in file:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        function_call = message.get(\"function_call\", None)\n",
        "\n",
        "        if (not content and not function_call) or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "783bf4af-0889-4ecc-9ab5-a7909124112a",
      "metadata": {
        "id": "783bf4af-0889-4ecc-9ab5-a7909124112a",
        "outputId": "537f948b-1480-4ca3-d9b3-9bc00006b850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tiktoken in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (0.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jagdish\\desktop\\finetuning\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num examples missing system message: 0\n",
            "Num examples missing user message: 0\n",
            "\n",
            "#### Distribution of num_messages_per_example:\n",
            "min / max: 3, 3\n",
            "mean / median: 3.0, 3.0\n",
            "p5 / p95: 3.0, 3.0\n",
            "\n",
            "#### Distribution of num_total_tokens_per_example:\n",
            "min / max: 48, 93\n",
            "mean / median: 68.58762886597938, 68.0\n",
            "p5 / p95: 58.6, 79.0\n",
            "\n",
            "#### Distribution of num_assistant_tokens_per_example:\n",
            "min / max: 20, 58\n",
            "mean / median: 37.1958762886598, 37.0\n",
            "p5 / p95: 27.6, 47.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken\n",
        "import tiktoken # for token counting\n",
        "import numpy as np\n",
        "\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# not exact!\n",
        "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in file:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 65536 for l in convo_lens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "167f21b0-dac7-4b0e-a625-5f9590ba4813",
      "metadata": {
        "id": "167f21b0-dac7-4b0e-a625-5f9590ba4813",
        "outputId": "8628001d-472b-4339-ccbc-1721496b3e05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset has ~6653 tokens that will be charged for during training\n",
            "By default, you'll train for 3 epochs on this dataset\n",
            "By default, you'll be charged for ~19959 tokens\n"
          ]
        }
      ],
      "source": [
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "MIN_DEFAULT_EPOCHS = 1\n",
        "MAX_DEFAULT_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(file)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "044ab51a-d32b-4596-9182-2fbffac7ccf3",
      "metadata": {
        "id": "044ab51a-d32b-4596-9182-2fbffac7ccf3"
      },
      "source": [
        "<h1>Finetuning the model</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6faaadd6-a3ef-4bcc-bf95-9e6f9e91d39b",
      "metadata": {
        "id": "6faaadd6-a3ef-4bcc-bf95-9e6f9e91d39b"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d652a5-e4ca-448b-a76b-1cc95d5446fc",
      "metadata": {
        "id": "68d652a5-e4ca-448b-a76b-1cc95d5446fc",
        "outputId": "a4f8ea1d-1432-4a7c-da01-36672fd962a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FileObject(id='file-IHFYm01BEBRTA9bQgaukDMK2', bytes=35974, created_at=1728021232, filename='synthetic_qa_pairs_finetune_gpt3.5.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
          ]
        }
      ],
      "source": [
        "response = client.files.create(\n",
        "    file=open(\"synthetic_qa_pairs_finetune_gpt3.5.jsonl\", \"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49b48033-3365-4696-bbb9-8dd53b05a55d",
      "metadata": {
        "id": "49b48033-3365-4696-bbb9-8dd53b05a55d",
        "outputId": "84d02da3-d08f-482a-c579-ed62ccb037ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "file-IHFYm01BEBRTA9bQgaukDMK2\n"
          ]
        }
      ],
      "source": [
        "file_id = response.id\n",
        "print(file_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b57ebd79-0a09-424b-a00c-c9e1f2221f6c",
      "metadata": {
        "id": "b57ebd79-0a09-424b-a00c-c9e1f2221f6c",
        "outputId": "51e8c841-3785-4923-eb52-e2fcedd69186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tune job is started\n"
          ]
        }
      ],
      "source": [
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=file_id,\n",
        "    model=\"gpt-4o-mini-2024-07-18\",\n",
        "    hyperparameters={\"n_epochs\": 2}\n",
        "    #validation_file\n",
        ")\n",
        "\n",
        "print(\"Fine-tune job is started\")\n",
        "ft_job_id = response.id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1bc8543-bc66-4cf6-96d9-4e5e978fab46",
      "metadata": {
        "id": "e1bc8543-bc66-4cf6-96d9-4e5e978fab46",
        "outputId": "d7f8b61a-b68e-4ddd-b496-60c23f2121fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-2jQi1tuvmoMzSF1m5w0YKf9D', created_at=1728021233, level='info', message='Validating training file: file-IHFYm01BEBRTA9bQgaukDMK2', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-JuHJdJgRAdRoz5yeNiZE0eX2', created_at=1728021233, level='info', message='Created fine-tuning job: ftjob-fVGoMJ1bNB8YWJdHNFzqpX3F', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_job_id, limit=10)\n",
        "response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ae54fc-5e9f-4745-a097-d742182bb793",
      "metadata": {
        "id": "f4ae54fc-5e9f-4745-a097-d742182bb793",
        "outputId": "40b84521-49c4-46c1-a325-3b77d6763e8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FineTuningJob(id='ftjob-fVGoMJ1bNB8YWJdHNFzqpX3F', created_at=1728021233, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=2, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-RE1PxkWIlBhkHiAvwXqkJEQi', result_files=[], seed=1786541492, status='validating_files', trained_tokens=None, training_file='file-IHFYm01BEBRTA9bQgaukDMK2', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n"
          ]
        }
      ],
      "source": [
        "response = client.fine_tuning.jobs.retrieve(ft_job_id)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45159744-7934-4f09-a9d5-fd46f47662e2",
      "metadata": {
        "id": "45159744-7934-4f09-a9d5-fd46f47662e2",
        "outputId": "d1024f90-73b4-4999-90a2-0602793f5e02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_files = response.result_files\n",
        "result_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d4822f0-d57e-4e7a-befd-e11df6a53164",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "9d4822f0-d57e-4e7a-befd-e11df6a53164",
        "outputId": "4eaa7a25-eaee-484a-b74a-e1c51c3893ce"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'response' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fc09d37533f9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfine_tuned_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfine_tuned_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfine_tuned_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
          ]
        }
      ],
      "source": [
        "fine_tuned_model = response.fine_tuned_model\n",
        "fine_tuned_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9714319f-d988-453b-ba22-2f9b7044c3e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9714319f-d988-453b-ba22-2f9b7044c3e6",
        "outputId": "afb16ca9-fa68-4fdb-afad-6c0519191712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28.0\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (4.66.5)\n",
            "Collecting aiohttp (from openai==0.28.0)\n",
            "  Downloading aiohttp-3.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (2024.8.30)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->openai==0.28.0)\n",
            "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->openai==0.28.0)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (24.2.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->openai==0.28.0)\n",
            "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai==0.28.0)\n",
            "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting yarl<2.0,>=1.12.0 (from aiohttp->openai==0.28.0)\n",
            "  Downloading yarl-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m941.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0 (from aiohttp->openai==0.28.0)\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28.0) (4.12.2)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
            "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.9/447.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, aiohappyeyeballs, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.10.8 aiosignal-1.3.1 async-timeout-4.0.3 frozenlist-1.4.1 multidict-6.1.0 openai-0.28.0 yarl-1.13.1\n",
            "The National Disability Insurance System (NDIS) is designed to manage and facilitate the delivery of services and supports for individuals with disabilities. It serves as a platform for registering users, accessing resources, tracking service delivery, and maintaining communication with service providers.\n",
            "\n",
            "To log in, navigate to the NDIS portal, enter your registered email address and password, and click the 'Login' button. If you encounter issues, use the 'Forgot Password' link to reset your password.\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28.0\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"\"\n",
        "\n",
        "user_content = \"What is the purpose of NDIS? And how to login into the system?\"\n",
        "\n",
        "# Create a chat completion using the fine-tuned model\n",
        "completion = openai.ChatCompletion.create(\n",
        "    model=\"ft:gpt-4o-mini-2024-07-18:kdyslab-ai::AEVYHYT8\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": user_content}\n",
        "    ]\n",
        "\n",
        ")\n",
        "\n",
        "# Print the response content\n",
        "print(completion.choices[0].message['content'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXn71kO2hm_O",
        "outputId": "f4d6a6e0-0981-48fd-b4e3-be80bb3aee92"
      },
      "id": "bXn71kO2hm_O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.51.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09825fbd-6ed7-4031-9392-279ab82b3bf6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "09825fbd-6ed7-4031-9392-279ab82b3bf6",
        "outputId": "30ec943a-0541-4bda-8a05-33e1b7206acd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "APIRemovedInV1",
          "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e9ec46937905>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Generate a response using the fine-tuned chat model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfine_tuned_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "\n",
        "# Validation data format: a list of dictionaries with 'input' and 'expected_output'\n",
        "validation_data = [\n",
        "    {\"input\": \"What is the purpose of NDIS?\", \"expected_output\": \"The NDIS is designed to provide support to Australians with a disability.\"},\n",
        "    {\"input\": \"How do I log in to the system?\", \"expected_output\": \"To log in, visit the login page and enter your credentials.\"},\n",
        "    # Add more validation data as needed\n",
        "]\n",
        "\n",
        "# Replace with your fine-tuned model name or ID (e.g., \"chatgpt4omini\")\n",
        "fine_tuned_model = \"\"\n",
        "\n",
        "# Store the predicted and expected outputs\n",
        "predictions = []\n",
        "expected_outputs = []\n",
        "\n",
        "# Loop over each example in the validation data\n",
        "for item in validation_data:\n",
        "    user_input = item['input']\n",
        "    expected_output = item['expected_output']\n",
        "\n",
        "    # Generate a response using the fine-tuned chat model\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=fine_tuned_model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ],\n",
        "        max_tokens=100,\n",
        "        temperature=0.5,\n",
        "    )\n",
        "\n",
        "    # Extract the content of the assistant's response\n",
        "    predicted_output = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Append the predictions and expected outputs\n",
        "    predictions.append(predicted_output)\n",
        "    expected_outputs.append(expected_output)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(expected_outputs, predictions)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(expected_outputs, predictions, average='weighted')\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75cbcbc9-bcb1-4417-b6cb-2cd3ade3af9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "75cbcbc9-bcb1-4417-b6cb-2cd3ade3af9c",
        "outputId": "87b71a98-f10b-4884-9839-b1aebecdc1c9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "APIRemovedInV1",
          "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5fadbaa535b4>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mexpected_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'expected_output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfine_tuned_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import re\n",
        "\n",
        "# Normalize text function\n",
        "def normalize_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text).lower().strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "# Validation data format: a list of dictionaries with 'input' and 'expected_output'\n",
        "validation_data = [\n",
        "    {\"input\": \"What is the purpose of NDIS?\", \"expected_output\": \"The NDIS is designed to provide support to Australians with a disability.\"},\n",
        "    {\"input\": \"How do I log in to the system?\", \"expected_output\": \"To log in, visit the login page and enter your credentials.\"},\n",
        "    # Add more validation data as needed\n",
        "]\n",
        "\n",
        "fine_tuned_model = \"\"\n",
        "\n",
        "predictions = []\n",
        "expected_outputs = []\n",
        "\n",
        "# Loop over each example in the validation data\n",
        "for item in validation_data:\n",
        "    user_input = item['input']\n",
        "    expected_output = item['expected_output']\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=fine_tuned_model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ],\n",
        "        max_tokens=100,\n",
        "        temperature=0.5,\n",
        "    )\n",
        "\n",
        "    predicted_output = response.choices[0].message.content.strip()\n",
        "\n",
        "    print(f\"User Input: {user_input}\")\n",
        "    print(f\"Expected Output: {expected_output}\")\n",
        "    print(f\"Predicted Output: {predicted_output}\\n\")\n",
        "\n",
        "    predictions.append(predicted_output)\n",
        "    expected_outputs.append(expected_output)\n",
        "\n",
        "# Normalize text for evaluation\n",
        "predictions_normalized = [normalize_text(pred) for pred in predictions]\n",
        "expected_outputs_normalized = [normalize_text(exp) for exp in expected_outputs]\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(expected_outputs_normalized, predictions_normalized)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    expected_outputs_normalized, predictions_normalized, average='weighted', zero_division=1\n",
        ")\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}